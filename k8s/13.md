# Lab 13: Kubernetes StatefulSet

## Task 1: Implement StatefulSet in Helm Chart

### 1) Understand StatefulSets

Understood.

### 2) Update Helm Chart

Command: 
```
helm install --dry-run --debug python-app ./helm-app-python
```
Output:
```
---
# Source: helm-app-python/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: python-app-helm-app-python
  labels:
    helm.sh/chart: helm-app-python-0.1.0
    app.kubernetes.io/name: helm-app-python
    app.kubernetes.io/instance: python-app
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podManagementPolicy: Parallel
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: helm-app-python
      app.kubernetes.io/instance: python-app
  template:
    metadata:
      annotations:
        vault.hashicorp.com/agent-init-first: "true"
        vault.hashicorp.com/agent-inject: "true"
        vault.hashicorp.com/agent-inject-secret-my-config.txt: internal/data/database/config
        vault.hashicorp.com/agent-inject-status: update
        vault.hashicorp.com/agent-inject-template-my-config.txt: |
          {{- with secret "internal/data/database/config" -}}
          postgresql://{{ .Data.data.username }}:{{ .Data.data.password }}arseniyrubtsov
          {{- end -}}
        vault.hashicorp.com/agent-pre-populate: "false"
        vault.hashicorp.com/role: internal-app
      labels:
        helm.sh/chart: helm-app-python-0.1.0
        app.kubernetes.io/name: helm-app-python
        app.kubernetes.io/instance: python-app
        app.kubernetes.io/version: "1.16.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: internal-app
      securityContext:
        {}
      containers:
        - name: helm-app-python
          securityContext:
            runAsNonRoot: false
            runAsUser: 0
          image: "arseniy5443/moscowtime:latest"
          imagePullPolicy: Always
          env:
            
            - name: "MY_PASS"
              valueFrom:
                secretKeyRef:
                  name: k8secretpython
                  key: password
          ports:
            - name: http
              containerPort: 5000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 30
          readinessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 30
          resources:
            limits:
              cpu: 200m
              memory: 256Mi
            requests:
              cpu: 100m
              memory: 128Mi
          volumeMounts:
            - mountPath: /app/volume
              name: python-app-visits
      volumes:
        - configMap:
            name: myconfigmap
          name: config
  volumeClaimTemplates:
  - metadata:
      name: python-app-visits
    spec:
      accessModes: [ReadWriteOnce]
      storageClassName: standard
      resources:
        requests:
          storage: 5Mi

NOTES:
1. Get the application URL by running these commands:
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch the status of by running 'kubectl get --namespace default svc -w python-app-helm-app-python'
  export SERVICE_IP=$(kubectl get svc --namespace default python-app-helm-app-python --template "{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}")
  echo http://$SERVICE_IP:5000
```

Applied best practices by moving values to variables in values.yml meaningfully.

## Task 2: StatefulSet Exploration and Optimization

### 1) Research and Documentation

Command:
```
kubectl get po,sts,svc,pvc
```
Output:
```
NAME                                        READY   STATUS    RESTARTS      AGE
pod/python-app-helm-app-python-0            1/1     Running   0             90s
pod/python-app-helm-app-python-1            1/1     Running   0             90s
pod/vault-0                                 1/1     Running   3 (26h ago)   14d
pod/vault-agent-injector-5cd8b87c6c-nzb6w   1/1     Running   3 (26h ago)   14d

NAME                                          READY   AGE
statefulset.apps/python-app-helm-app-python   2/2     93s
statefulset.apps/vault                        1/1     14d

NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/kubernetes                   ClusterIP      10.96.0.1        <none>        443/TCP             29d
service/python-app-helm-app-python   LoadBalancer   10.99.237.151    <pending>     5000:30390/TCP      93s
service/vault                        ClusterIP      10.104.79.3      <none>        8200/TCP,8201/TCP   14d
service/vault-agent-injector-svc     ClusterIP      10.101.181.232   <none>        443/TCP             14d
service/vault-internal               ClusterIP      None             <none>        8200/TCP,8201/TCP   14d

NAME                                                                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/python-app-visits-python-app-helm-app-python-0   Bound    pvc-7052236b-2b00-450e-9605-8aff5ef5c96b   5Mi        RWO            standard       26h
persistentvolumeclaim/python-app-visits-python-app-helm-app-python-1   Bound    pvc-e2040f63-faad-499d-a6fe-780a4ea89566   5Mi        RWO            standard       26h
```

Command:
```
minikube service python-app-helm-app-python
```
Output:
```
|-----------|----------------------------|-------------|---------------------------|
| NAMESPACE |            NAME            | TARGET PORT |            URL            |
|-----------|----------------------------|-------------|---------------------------|
| default   | python-app-helm-app-python | http/5000   | http://192.168.49.2:30390 |
|-----------|----------------------------|-------------|---------------------------|
üèÉ  Starting tunnel for service python-app-helm-app-python.
|-----------|----------------------------|-------------|------------------------|
| NAMESPACE |            NAME            | TARGET PORT |          URL           |
|-----------|----------------------------|-------------|------------------------|
| default   | python-app-helm-app-python |             | http://127.0.0.1:56182 |
|-----------|----------------------------|-------------|------------------------|
üéâ  Opening service default/python-app-helm-app-python in default browser...
‚ùó  Because you are using a Docker driver on darwin, the terminal needs to be open to run it.
```

Command:
```
kubectl exec -it pod/python-app-helm-app-python-0 -- cat /app/volume/visits
```
Output:
```
68.0
```

Command:
```
kubectl exec -it pod/python-app-helm-app-python-1 -- cat /app/volume/visits
```
Output:
```
69.0
```

I already implemented Parallel Operations in my StatefulSet that's why they have pretty the same number of visits by "livenessProbe" and "readinessProbe". And loadBalancer balances the visits from user between them. 

In case, without implementation of Parallel Operations, they would have different numbers due to that one of them is started earlier and got more visits from "livenessProbe" and "readinessProbe".

### 2) Ordering Guarantee and Parallel Operations

Explain why ordering guarantees are unnecessary for your app:
```
In our application, the absence of ordering guarantees stems from the stateless nature of its components. Since these components operate without reliance on a particular startup or shutdown sequence, the application can dynamically scale up or down without being constrained by a predetermined order of operations. This inherent flexibility allows for independent scaling of components, fostering a more adaptable and efficient system architecture.
```

Implement a way to instruct the StatefulSet controller to launch or terminate all Pods in parallel:
```
apiVersion: apps/v1
kind: StatefulSet
spec:
  podManagementPolicy: Parallel
```
In yaml I added podManagementPolicy.

Command:
```
kubectl get po
```
Output:
```
NAME                                    READY   STATUS    RESTARTS      AGE
python-app-helm-app-python-0            1/1     Running   0             33s
python-app-helm-app-python-1            1/1     Running   0             33s
vault-0                                 1/1     Running   3 (26h ago)   14d
vault-agent-injector-5cd8b87c6c-nzb6w   1/1     Running   3 (26h ago)   14d
```

## Bonus

### Apply the main steps to your extra app

Applied everything to my extra app.

Command: 
```
helm install --dry-run --debug javascript-app ./helm-app-javascript
```
Output:
```
---
# Source: helm-app-javascript/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: javascript-app-helm-app-javascript
  labels:
    helm.sh/chart: helm-app-javascript-0.1.0
    app.kubernetes.io/name: helm-app-javascript
    app.kubernetes.io/instance: javascript-app
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podManagementPolicy: Parallel
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: helm-app-javascript
      app.kubernetes.io/instance: javascript-app
  template:
    metadata:
      labels:
        helm.sh/chart: helm-app-javascript-0.1.0
        app.kubernetes.io/name: helm-app-javascript
        app.kubernetes.io/instance: javascript-app
        app.kubernetes.io/version: "1.16.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: javascript-app-helm-app-javascript
      securityContext:
        {}
      containers:
        - name: helm-app-javascript
          securityContext:
            runAsNonRoot: false
            runAsUser: 0
          image: "arseniy5443/randomquote:latest"
          imagePullPolicy: Always
          env:
            
            - name: "MY_PASS"
              valueFrom:
                secretKeyRef:
                  name: k8secretjavascript
                  key: password
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 20
          readinessProbe:
            httpGet:
              path: /
              port: http
            initialDelaySeconds: 20
          resources:
            limits:
              cpu: 200m
              memory: 256Mi
            requests:
              cpu: 100m
              memory: 128Mi
          volumeMounts:
            - mountPath: /app/volume
              name: javascript-app-visits
  volumeClaimTemplates:
  - metadata:
      name: javascript-app-visits
    spec:
      accessModes: [ReadWriteOnce]
      storageClassName: standard
      resources:
        requests:
          storage: 5Mi

NOTES:
1. Get the application URL by running these commands:
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch the status of by running 'kubectl get --namespace default svc -w javascript-app-helm-app-javascript'
  export SERVICE_IP=$(kubectl get svc --namespace default javascript-app-helm-app-javascript --template "{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}")
  echo http://$SERVICE_IP:3000
```

Command:
```
kubectl get po,sts,svc,pvc
```
Output:
```
NAME                                        READY   STATUS    RESTARTS      AGE
pod/javascript-app-helm-app-javascript-0    1/1     Running   0             56s
pod/javascript-app-helm-app-javascript-1    1/1     Running   0             56s
pod/vault-0                                 1/1     Running   3 (27h ago)   14d
pod/vault-agent-injector-5cd8b87c6c-nzb6w   1/1     Running   3 (27h ago)   14d

NAME                                                  READY   AGE
statefulset.apps/javascript-app-helm-app-javascript   2/2     56s
statefulset.apps/vault                                1/1     14d

NAME                                         TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
service/javascript-app-helm-app-javascript   LoadBalancer   10.105.37.196    <pending>     3000:30183/TCP      56s
service/kubernetes                           ClusterIP      10.96.0.1        <none>        443/TCP             29d
service/vault                                ClusterIP      10.104.79.3      <none>        8200/TCP,8201/TCP   14d
service/vault-agent-injector-svc             ClusterIP      10.101.181.232   <none>        443/TCP             14d
service/vault-internal                       ClusterIP      None             <none>        8200/TCP,8201/TCP   14d

NAME                                                                               STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/javascript-app-visits-javascript-app-helm-app-javascript-0   Bound    pvc-c9614d28-8b3d-4bb3-b64c-973b92a4d17f   5Mi        RWO            standard       56s
persistentvolumeclaim/javascript-app-visits-javascript-app-helm-app-javascript-1   Bound    pvc-57a5eb91-e93e-4c33-868b-aff0a5511729   5Mi        RWO            standard       56s
```


### Explore Update Strategies

1) Blue/Green Deployment:

- Blue/Green deployment involves the creation of two identical but separate environments. While one environment (Blue) is active, the other (Green) is updated. Users are gradually shifted from the old environment to the new one, minimizing downtime and providing a straightforward mechanism for rollback if issues arise during the update.

2) Canary Deployment:

- Canary deployment represents a gradual delivery model where a small subset of users interacts with a newer version of the application while the main user base continues with the current version. If the new version proves successful with the smaller group, it is gradually rolled out to a larger audience. This approach enables early issue detection and ensures a careful, step-by-step rollout.

3) Rolling Deployment:

- Rolling deployment is a default strategy that ensures the seamless update of pods without causing downtime. This method systematically replaces older versions of the application with newer ones, maintaining continuous service availability. By gradually transitioning from the old to the new version, the update process is controlled, allowing for a smooth and reliable deployment.

4) Recreate Deployment:

- Recreate deployment takes a more instantaneous approach to updating applications, incurring some downtime. This method involves terminating all existing pods and then launching new ones with the updated version. While it introduces a brief interruption in service, it provides a straightforward way to ensure that the entire application is quickly and uniformly updated.

5) Ramped Slow Rollout:

- Ramped slow rollout is a technique designed to introduce replicas of the new version gradually while concurrently phasing out the old replicas. This strategy aims to minimize user impact by progressively scaling up the new version and scaling down the old version. By carefully managing the transition, this method enables a controlled and smooth update process.

6) Shadow Deployment:

- Shadow deployment involves introducing the latest application version, known as the "shadow" version, to process real-world traffic in parallel with the current version. Unlike other strategies, this method operates without impacting end-users, providing an effective way to test the new version's performance in a live environment before a full deployment.